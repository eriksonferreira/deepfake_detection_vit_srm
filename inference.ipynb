{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image, \\\n",
    "    preprocess_image\n",
    "import argparse\n",
    "import datetime\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from timm.data import Mixup\n",
    "from timm.models import create_model\n",
    "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
    "from timm.scheduler import create_scheduler\n",
    "from timm.optim import create_optimizer\n",
    "from timm.utils import NativeScaler, get_state_dict\n",
    "\n",
    "\n",
    "import models\n",
    "import utils\n",
    "import sys\n",
    "import cv2\n",
    "from datasetsV2 import get_transform_to_eval, get_transform_to_eval_NO_SRM, get_transform_to_eval_Sobel\n",
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc,  log_loss\n",
    "import math\n",
    "import time\n",
    "import ffmpeg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ffmpeg-python in /home/eferreira/anaconda3/envs/crossvit/lib/python3.8/site-packages (0.2.0)\n",
      "Requirement already satisfied: future in /home/eferreira/anaconda3/envs/crossvit/lib/python3.8/site-packages (from ffmpeg-python) (0.18.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image_transform(image_input, transform):\n",
    "    \"\"\"\n",
    "    Pré-processa uma imagem a partir de um caminho ou de um ROI já carregado.\n",
    "\n",
    "    Parâmetros:\n",
    "        - image_input: str (caminho da imagem) ou np.ndarray (ROI)\n",
    "        - transform: função de transformação (ex: Albumentations)\n",
    "\n",
    "    Retorno:\n",
    "        - Imagem transformada\n",
    "    \"\"\"\n",
    "\n",
    "    # Se a entrada for um caminho, carregamos a imagem\n",
    "    if isinstance(image_input, str):\n",
    "        image = Image.open(image_input).convert('RGB').resize((224, 224))\n",
    "        image = np.array(image)  # Converte para numpy\n",
    "    elif isinstance(image_input, np.ndarray):\n",
    "        image = cv2.resize(image_input, (224, 224))  # Redimensiona diretamente\n",
    "    else:\n",
    "        raise ValueError(\"image_input deve ser um caminho (str) ou uma imagem (np.ndarray)\")\n",
    "\n",
    "    # Aplica a transformação\n",
    "    augmented = transform(image=image)\n",
    "    \n",
    "    return augmented['image'].squeeze(0)  # Retorna a imagem transformada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_transform(tensor, height=14, width=14):\n",
    "    result = tensor[:, 1:, :].reshape(tensor.size(0),\n",
    "                                      height, width, tensor.size(2))\n",
    "\n",
    "    # Bring the channels to the first dimension,\n",
    "    # like in CNNs.\n",
    "    result = result.transpose(2, 3).transpose(1, 2)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(logs_path):\n",
    "    if 'baseline' in logs_path:\n",
    "        print(\"using without srm\")\n",
    "        return get_transform_to_eval_NO_SRM(224)\n",
    "    elif \"input\" in logs_path and \"srm\" in logs_path:\n",
    "        print(\"using input srm\")\n",
    "        return get_transform_to_eval(224)\n",
    "    elif \"input\" in logs_path and \"sobel\" in logs_path:\n",
    "        print(\"using input sobel\")\n",
    "        return get_transform_to_eval_Sobel(224)\n",
    "    elif \"branch\" in logs_path and \"srm\" in logs_path:\n",
    "        print(\"using branch filter\")\n",
    "        return get_transform_to_eval_NO_SRM(224)\n",
    "    elif \"branch\" in logs_path and \"sobel\" in logs_path:\n",
    "        print(\"using branch filter\")\n",
    "        return get_transform_to_eval_NO_SRM(224)\n",
    "    else:\n",
    "        return get_transform_to_eval_NO_SRM(224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {}\n",
    "prob_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_image_inference(img, transform, model):\n",
    "\n",
    "    input_tensor = preprocess_image_transform(img, transform)\n",
    "    input_tensor = input_tensor.unsqueeze(0) \n",
    "    # input_tensor = torch.stack((input_tensor))\n",
    "\n",
    "    img = input_tensor.to(device)\n",
    "    results = model(img)\n",
    "    # print(results)\n",
    "    pred = torch.sigmoid(results)\n",
    "    # print(pred)\n",
    "    pred = pred.to('cpu')\n",
    "    \n",
    "    detected = \"FAKE\" if pred.item() > 0.5 else \"REAL\"\n",
    "    # print(detected)\n",
    "\n",
    "    return pred.item(), detected\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_deepfake(imgs_paths, video_name, count_thresh, n_images, transform, model):\n",
    "    count_fake = 0\n",
    "    count_real = 0\n",
    "    # for img in imgs_paths:\n",
    "    if n_images <= len(imgs_paths):\n",
    "        imgs_paths = random.sample(imgs_paths, n_images)\n",
    "\n",
    "    input_tensor = [preprocess_image_transform(x, transform) for x in imgs_paths]\n",
    "    input_tensor = torch.stack((input_tensor))\n",
    "\n",
    "    # print(input_tensor.shape)\n",
    "    # for img in input_tensor:\n",
    "    img = input_tensor.to(device)\n",
    "    results = model(img)\n",
    "    pred = torch.sigmoid(results)\n",
    "    # print(pred)\n",
    "    pred = pred.to('cpu')\n",
    "    for result in pred:\n",
    "        detected = \"FAKE\" if result.item() > 0.5 else \"REAL\"\n",
    "        if detected == \"FAKE\":\n",
    "            count_fake += 1\n",
    "        else:\n",
    "            count_real += 1\n",
    "\n",
    "\n",
    "    if count_fake > count_real:\n",
    "        result_dict[video_name] = 1\n",
    "        # print(\"FAKE\")\n",
    "    else:\n",
    "        result_dict[video_name] = 0\n",
    "        # print(\"REAL\")\n",
    "    \n",
    "    # Calculando a média das predições e armazenando no dicionário\n",
    "    pred_mean = np.mean(pred.detach().numpy().tolist())\n",
    "    prob_dict[video_name] = pred_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: crossvit_18_dagger_224_srm\n",
      "\n",
      "ViT with 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fvcore.common.checkpoint:[Checkpointer] Loading from /tmp/tmp8v31a9sx ...\n",
      "WARNING:fvcore.common.checkpoint:Skip loading parameter 'srm.kernel' to the model due to incompatible shapes: (3, 3, 5, 5) in the checkpoint but (3, 1, 5, 5) in the model! You might want to double check if this is expected.\n",
      "WARNING:fvcore.common.checkpoint:Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34msrm.kernel\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using branch filter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.37it/s]\n"
     ]
    }
   ],
   "source": [
    "logs_path = \"/home/eferreira/master/cross-vit/CrossViT/old_logs/24_srm_l_branch_simple\"\n",
    "backbone = ''\n",
    "args = open(os.path.join(logs_path, 'args.txt'),'r')\n",
    "for txt in args:\n",
    "    if \"model\" in txt:\n",
    "        print(txt)\n",
    "        backbone = txt.split(' ')[-1][:-1]\n",
    "\n",
    "model = create_model(\n",
    "backbone,\n",
    "pretrained=True,\n",
    "num_classes=1\n",
    ")\n",
    "model_path = os.path.join(logs_path, 'model_best.pth')\n",
    "checkpoint = torch.load(model_path, map_location='cpu')\n",
    "utils.load_checkpoint(model, checkpoint['model'])\n",
    "model.eval()\n",
    "\n",
    "transform = get_transform(logs_path)\n",
    "model.to(device)\n",
    "\n",
    "source_dir = '/home/eferreira/master/cross-vit/CrossViT/obama/faces'\n",
    "\n",
    "\n",
    "for video in tqdm(os.listdir(source_dir)):\n",
    "# print(video)\n",
    "    parent_name = os.path.join(source_dir, video)\n",
    "    # print(parent_name)\n",
    "    imgs = os.listdir(parent_name)\n",
    "    imgs = [os.path.join(parent_name, x) for x in imgs]\n",
    "    # print(imgs)\n",
    "    detect_deepfake(imgs, video, 18, 30,transform, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'obama': 1}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'obama': 0.8166824309776227}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = \"/home/eferreira/master/cross-vit/CrossViT/obama/boxes/obama.json\"\n",
    "video_path = \"/home/eferreira/master/cross-vit/CrossViT/obama/obama.mp4\" \n",
    "output_video_path = \"/home/eferreira/master/cross-vit/CrossViT/obama/output_video.mp4\" \n",
    "final_video_path = \"/home/eferreira/master/cross-vit/CrossViT/obama/obama_detected.mp4\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_width = 1280  # Largura da imagem na qual as bounding boxes foram geradas\n",
    "original_height = 720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "with open(json_path, \"r\") as f:\n",
    "    bboxes = json.load(f)\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "print(fps)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "\n",
    "\n",
    "\n",
    "frame_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = cv2.VideoWriter(output_video_path, fourcc, 23.98, (width, height))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    init = time.time()\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break  \n",
    "\n",
    "    frame_id += 1\n",
    "    str_frame_id = str(frame_id)\n",
    "\n",
    "    if str_frame_id in bboxes and bboxes[str_frame_id] is not None:\n",
    "        for bbox in bboxes[str_frame_id]:\n",
    "            xmin, ymin, xmax, ymax = [int(b * 2) for b in bbox]\n",
    "            w = xmax - xmin\n",
    "            h = ymax - ymin\n",
    "            p_h = 0\n",
    "            p_w = 0\n",
    "            \n",
    "            if h > w:\n",
    "                p_w = int((h - w) / 2)\n",
    "            elif h < w:\n",
    "                p_h = int((w - h) / 2)\n",
    "\n",
    "            x1 = max(xmin - p_w, 0)\n",
    "            y1 = max(ymin - p_h, 0)\n",
    "            x2 = min(xmax + p_w, frame.shape[1])\n",
    "            y2 = min(ymax + p_h, frame.shape[0])\n",
    "            roi = frame[y1:y2, x1:x2]\n",
    "\n",
    "            roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            pred, detection = single_image_inference(roi, transform, model)\n",
    "\n",
    "            text_x = x1\n",
    "            text_y = y2 + 20\n",
    "\n",
    "            text = f\"Pred: {pred:.2f} - {detection}\"\n",
    "\n",
    "            color = (0, 255, 0) if detection == \"REAL\" else (0, 0, 255)\n",
    "\n",
    "            end = time.time()\n",
    "\n",
    "            cv2.rectangle(frame, \n",
    "                        (max(xmin - p_w, 0), max(ymin - p_h, 0)), \n",
    "                        (min(xmax + p_w, frame.shape[1]), min(ymax + p_h, frame.shape[0])),\n",
    "                        color, 2)\n",
    "            \n",
    "            cv2.putText(frame, text, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        0.5, color, 2, cv2.LINE_AA)\n",
    "\n",
    "            inference_time = round((end - init), 5) * 1000\n",
    "            inference_time = round(inference_time, 2)\n",
    "            inference_text = f\"Inference time: {inference_time}ms\"\n",
    "            cv2.putText(frame, inference_text, (20, 20), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    # cv2.imshow(\"Video com Bounding Boxes\", frame)\n",
    "    out.write(frame)\n",
    "    \n",
    "\n",
    "    # if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "    #     break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.98\n"
     ]
    }
   ],
   "source": [
    "out_vid = cv2.VideoCapture(output_video_path)\n",
    "fps_out = out_vid.get(cv2.CAP_PROP_FPS)\n",
    "print(fps_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 5.1.2 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 11.3.0 (conda-forge gcc 11.3.0-19)\n",
      "  configuration: --prefix=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/x86_64-conda-linux-gnu-cc --cxx=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/x86_64-conda-linux-gnu-c++ --nm=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/x86_64-conda-linux-gnu-nm --ar=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/x86_64-conda-linux-gnu-ar --disable-doc --disable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libfontconfig --enable-libopenh264 --enable-gnutls --enable-libmp3lame --enable-libvpx --enable-pthreads --enable-vaapi --enable-gpl --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libopus --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/pkg-config\n",
      "  libavutil      57. 28.100 / 57. 28.100\n",
      "  libavcodec     59. 37.100 / 59. 37.100\n",
      "  libavformat    59. 27.100 / 59. 27.100\n",
      "  libavdevice    59.  7.100 / 59.  7.100\n",
      "  libavfilter     8. 44.100 /  8. 44.100\n",
      "  libswscale      6.  7.100 /  6.  7.100\n",
      "  libswresample   4.  7.100 /  4.  7.100\n",
      "  libpostproc    56.  6.100 / 56.  6.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/home/eferreira/master/cross-vit/CrossViT/obama/output_video.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf59.27.100\n",
      "  Duration: 00:01:12.44, start: 0.000000, bitrate: 2873 kb/s\n",
      "  Stream #0:0[0x1](und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 1280x720 [SAR 1:1 DAR 16:9], 2873 kb/s, 23.98 fps, 23.98 tbr, 19184 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:0 (mpeg4) -> fps:default\n",
      "  fps:default -> Stream #0:0 (libx264)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x5fd0d9adc0c0] using SAR=1/1\n",
      "[libx264 @ 0x5fd0d9adc0c0] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x5fd0d9adc0c0] profile High, level 3.1, 4:2:0, 8-bit\n",
      "[libx264 @ 0x5fd0d9adc0c0] 264 - core 164 r3095 baee400 - H.264/MPEG-4 AVC codec - Copyleft 2003-2022 - http://www.videolan.org/x264.html - options: cabac=1 ref=5 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=8 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=2 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=22 lookahead_threads=3 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=3 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=23 scenecut=40 intra_refresh=0 rc_lookahead=50 rc=crf mbtree=1 crf=18.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'temp_output_video.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf59.27.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 1280x720 [SAR 1:1 DAR 16:9], q=2-31, 23.98 fps, 19184 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc59.37.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame= 1737 fps=265 q=-1.0 Lsize=   13776kB time=00:01:12.31 bitrate=1560.7kbits/s speed=  11x    \n",
      "video:13756kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.146243%\n",
      "[libx264 @ 0x5fd0d9adc0c0] frame I:11    Avg QP: 9.26  size: 47646\n",
      "[libx264 @ 0x5fd0d9adc0c0] frame P:651   Avg QP:15.44  size: 14406\n",
      "[libx264 @ 0x5fd0d9adc0c0] frame B:1075  Avg QP:17.62  size:  3891\n",
      "[libx264 @ 0x5fd0d9adc0c0] consecutive B-frames: 10.8% 14.7% 16.2% 58.3%\n",
      "[libx264 @ 0x5fd0d9adc0c0] mb I  I16..4: 42.0% 46.7% 11.2%\n",
      "[libx264 @ 0x5fd0d9adc0c0] mb P  I16..4:  3.1%  7.0%  0.9%  P16..4: 25.7% 11.1%  5.8%  0.0%  0.0%    skip:46.3%\n",
      "[libx264 @ 0x5fd0d9adc0c0] mb B  I16..4:  0.7%  1.1%  0.1%  B16..8: 29.4%  3.4%  0.4%  direct: 2.4%  skip:62.4%  L0:51.8% L1:42.2% BI: 5.9%\n",
      "[libx264 @ 0x5fd0d9adc0c0] 8x8 transform intra:60.0% inter:62.9%\n",
      "[libx264 @ 0x5fd0d9adc0c0] direct mvs  spatial:98.9% temporal:1.1%\n",
      "[libx264 @ 0x5fd0d9adc0c0] coded y,uvDC,uvAC intra: 35.2% 38.0% 17.8% inter: 6.6% 10.9% 2.2%\n",
      "[libx264 @ 0x5fd0d9adc0c0] i16 v,h,dc,p: 53% 35%  8%  4%\n",
      "[libx264 @ 0x5fd0d9adc0c0] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 25% 28% 37%  2%  1%  2%  2%  2%  2%\n",
      "[libx264 @ 0x5fd0d9adc0c0] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 33% 32% 13%  3%  4%  5%  4%  3%  4%\n",
      "[libx264 @ 0x5fd0d9adc0c0] i8c dc,h,v,p: 43% 31% 23%  3%\n",
      "[libx264 @ 0x5fd0d9adc0c0] Weighted P-Frames: Y:1.1% UV:0.9%\n",
      "[libx264 @ 0x5fd0d9adc0c0] ref P L0: 62.9%  9.0% 15.1%  6.4%  5.2%  1.3%\n",
      "[libx264 @ 0x5fd0d9adc0c0] ref B L0: 77.7% 15.0%  5.7%  1.5%\n",
      "[libx264 @ 0x5fd0d9adc0c0] ref B L1: 95.3%  4.7%\n",
      "[libx264 @ 0x5fd0d9adc0c0] kb/s:1555.65\n",
      "ffmpeg version 5.1.2 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 11.3.0 (conda-forge gcc 11.3.0-19)\n",
      "  configuration: --prefix=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/x86_64-conda-linux-gnu-cc --cxx=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/x86_64-conda-linux-gnu-c++ --nm=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/x86_64-conda-linux-gnu-nm --ar=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/x86_64-conda-linux-gnu-ar --disable-doc --disable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libfontconfig --enable-libopenh264 --enable-gnutls --enable-libmp3lame --enable-libvpx --enable-pthreads --enable-vaapi --enable-gpl --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libopus --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/pkg-config\n",
      "  libavutil      57. 28.100 / 57. 28.100\n",
      "  libavcodec     59. 37.100 / 59. 37.100\n",
      "  libavformat    59. 27.100 / 59. 27.100\n",
      "  libavdevice    59.  7.100 / 59.  7.100\n",
      "  libavfilter     8. 44.100 /  8. 44.100\n",
      "  libswscale      6.  7.100 /  6.  7.100\n",
      "  libswresample   4.  7.100 /  4.  7.100\n",
      "  libpostproc    56.  6.100 / 56.  6.100\n",
      "Trailing option(s) found in the command: may be ignored.\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'temp_output_video.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf59.27.100\n",
      "  Duration: 00:01:12.44, start: 0.000000, bitrate: 1557 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(progressive), 1280x720 [SAR 1:1 DAR 16:9], 1555 kb/s, 23.98 fps, 23.98 tbr, 19184 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc59.37.100 libx264\n",
      "Input #1, mov,mp4,m4a,3gp,3g2,mj2, from '/home/eferreira/master/cross-vit/CrossViT/obama/obama.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso6iso2avc1mp41\n",
      "    encoder         : Lavf60.16.100\n",
      "  Duration: 00:01:12.56, start: 0.000000, bitrate: 543 kb/s\n",
      "  Stream #1:0[0x1](und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 1280x720 [SAR 1:1 DAR 16:9], 412 kb/s, 23.98 fps, 23.98 tbr, 24k tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : ISO Media file produced by Google Inc.\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #1:1[0x2](eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 127 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : ISO Media file produced by Google Inc.\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (copy)\n",
      "  Stream #1:1 -> #0:1 (aac (native) -> aac (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp4, to '/home/eferreira/master/cross-vit/CrossViT/obama/obama_detected.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf59.27.100\n",
      "  Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(progressive), 1280x720 [SAR 1:1 DAR 16:9], q=2-31, 1555 kb/s, 23.98 fps, 23.98 tbr, 19184 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc59.37.100 libx264\n",
      "  Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : ISO Media file produced by Google Inc.\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc59.37.100 aac\n",
      "frame= 1139 fps=1138 q=-1.0 size=    9216kB time=00:00:47.37 bitrate=1593.7kbits/s speed=47.4x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Vídeo final salvo em: /home/eferreira/master/cross-vit/CrossViT/obama/obama_detected.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame= 1737 fps=1162 q=-1.0 Lsize=   14936kB time=00:01:12.55 bitrate=1686.3kbits/s speed=48.5x    \n",
      "video:13756kB audio:1126kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.366684%\n",
      "[aac @ 0x5b76839545c0] Qavg: 922.834\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ffmpeg.input(output_video_path).filter(\"fps\", fps=23.98, round=\"up\").output(\n",
    "        \"temp_output_video.mp4\", vcodec=\"libx264\", preset=\"slow\", crf=18\n",
    "    ).run(overwrite_output=True)\n",
    "\n",
    "    video_fixed = ffmpeg.input(\"temp_output_video.mp4\")\n",
    "    audio_original = ffmpeg.input(video_path).audio \n",
    "\n",
    "    ffmpeg.output(video_fixed, audio_original, final_video_path, vcodec=\"copy\", acodec=\"aac\").global_args(\"-shortest\").run(overwrite_output=True)\n",
    "\n",
    "    print(f\"✅ Vídeo final salvo em: {final_video_path}\")\n",
    "\n",
    "except ffmpeg.Error as e:\n",
    "    print(\"⚠️ Erro ao processar com FFmpeg:\")\n",
    "    if e.stderr:\n",
    "        print(e.stderr.decode())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crossvit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
