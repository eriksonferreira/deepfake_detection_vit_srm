{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.10 (you have 1.4.8). Upgrade using: pip install --upgrade albumentations\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import traceback\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.cuda\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import blazeface\n",
    "from blazeface import BlazeFace, VideoReader, FaceExtractor\n",
    "from isplutils.utils import adapt_bb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "CONFIG_FILE = '.config_ipynb'\n",
    "if os.path.isfile(CONFIG_FILE):\n",
    "    with open(CONFIG_FILE) as f:\n",
    "        sys.argv = f.read().split()\n",
    "else:\n",
    "    sys.argv = ['test_args.py', 'input_file', '--source', '/home/eferreira/master/storage/celeb/celebdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_args(argv):\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--source', type=Path, help='Videos root directory', required=True)\n",
    "    parser.add_argument('--videodf', type=Path, help='Path to read the videos DataFrame', required=True)\n",
    "    parser.add_argument('--facesfolder', type=Path, help='Faces output root directory', required=True)\n",
    "    parser.add_argument('--facesdf', type=Path, help='Path to save the output DataFrame of faces', required=True)\n",
    "    parser.add_argument('--checkpoint', type=Path, help='Path to save the temporary per-video outputs', required=True)\n",
    "\n",
    "    parser.add_argument('--fpv', type=int, default=32, help='Frames per video')\n",
    "    parser.add_argument('--device', type=torch.device,\n",
    "                        default=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu'),\n",
    "                        help='Device to use for face extraction')\n",
    "    parser.add_argument('--collateonly', help='Only perform collation of pre-existing results', action='store_true')\n",
    "    parser.add_argument('--noindex', help='Do not rebuild the index', action='store_false')\n",
    "    parser.add_argument('--batch', type=int, help='Batch size', default=16)\n",
    "    parser.add_argument('--threads', type=int, help='Number of threads', default=8)\n",
    "    parser.add_argument('--offset', type=int, help='Offset to start extraction', default=0)\n",
    "    parser.add_argument('--num', type=int, help='Number of videos to process', default=0)\n",
    "    parser.add_argument('--lazycheck', action='store_true', help='Lazy check of existing video indexes')\n",
    "    parser.add_argument('--deepcheck', action='store_true', help='Try to open every image')\n",
    "\n",
    "    return parser.parse_args(argv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_jpg(args: Tuple[Image.Image, Path or str]):\n",
    "    image, path = args\n",
    "    image.save(path, quality=95, subsampling='4:4:4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(item: Tuple[pd.Index, pd.Series],\n",
    "                  source_dir: Path,\n",
    "                  facedestination_dir: Path,\n",
    "                  checkpoint_folder: Path,\n",
    "                  face_size: int,\n",
    "                  face_extractor: FaceExtractor,\n",
    "                  lazycheck: bool = False,\n",
    "                  deepcheck: bool = False,\n",
    "                  ) -> (pd.DataFrame, Path, List[Tuple[Image.Image, Path]]) or None:\n",
    "    # Instatiate Index and Series\n",
    "    idx, record = item\n",
    "\n",
    "    # Checkpoint\n",
    "    video_faces_checkpoint_path = checkpoint_folder.joinpath(record['path']).with_suffix('.faces.pkl')\n",
    "\n",
    "    if not lazycheck:\n",
    "        if video_faces_checkpoint_path.exists():\n",
    "            try:\n",
    "                df_video_faces = pd.read_pickle(str(video_faces_checkpoint_path))\n",
    "                for _, r in df_video_faces.iterrows():\n",
    "                    face_path = facedestination_dir.joinpath(r.name)\n",
    "                    assert (face_path.exists())\n",
    "                    if deepcheck:\n",
    "                        img = Image.open(face_path)\n",
    "                        img_arr = np.asarray(img)\n",
    "                        assert (img_arr.ndim == 3)\n",
    "                        assert (np.prod(img_arr.shape) > 0)\n",
    "            except Exception as e:\n",
    "                print('Error while checking: {}'.format(video_faces_checkpoint_path))\n",
    "                print(e)\n",
    "                video_faces_checkpoint_path.unlink()\n",
    "\n",
    "    if not (video_faces_checkpoint_path.exists()):\n",
    "\n",
    "        try:\n",
    "\n",
    "            video_face_dict_list = []\n",
    "\n",
    "            # Load faces\n",
    "            current_video_path = source_dir.joinpath(record['path'])\n",
    "            if not current_video_path.exists():\n",
    "                raise FileNotFoundError(f'Unable to find {current_video_path}.'\n",
    "                                        f'Are you sure that {source_dir} is the correct source directory for the video '\n",
    "                                        f'you indexed in the dataframe?')\n",
    "\n",
    "            frames = face_extractor.process_video(current_video_path)\n",
    "\n",
    "            if len(frames) == 0:\n",
    "                return\n",
    "\n",
    "            face_extractor.keep_only_best_face(frames)\n",
    "            for frame_idx, frame in enumerate(frames):\n",
    "                frames[frame_idx]['subjects'] = [0] * len(frames[frame_idx]['detections'])\n",
    "\n",
    "            # Extract and save faces, bounding boxes, keypoints\n",
    "            images_to_save: List[Tuple[Image.Image, Path]] = []\n",
    "            for frame_idx, frame in enumerate(frames):\n",
    "                if len(frames[frame_idx]['detections']):\n",
    "                    fullframe = Image.fromarray(frames[frame_idx]['frame'])\n",
    "\n",
    "                    # Preserve the only found face even if not a good one, otherwise preserve only clusters > -1\n",
    "                    subjects = np.unique(frames[frame_idx]['subjects'])\n",
    "                    if len(subjects) > 1:\n",
    "                        subjects = np.asarray([s for s in subjects if s > -1])\n",
    "\n",
    "                    for face_idx, _ in enumerate(frame['faces']):\n",
    "                        subj_id = frames[frame_idx]['subjects'][face_idx]\n",
    "                        if subj_id in subjects:  # Exclude outliers if other faces detected\n",
    "                            face_path = facedestination_dir.joinpath(record['path'], 'fr{:03d}_subj{:1d}.jpg'.format(\n",
    "                                frames[frame_idx]['frame_idx'], subj_id))\n",
    "\n",
    "                            face_dict = {'facepath': str(face_path.relative_to(facedestination_dir)), 'video': idx,\n",
    "                                         'label': record['label'], 'videosubject': subj_id,\n",
    "                                         'original': record['original']}\n",
    "                            # add attibutes for ff++\n",
    "                            if 'class' in record.keys():\n",
    "                                face_dict.update({'class': record['class']})\n",
    "                            if 'source' in record.keys():\n",
    "                                face_dict.update({'source': record['source']})\n",
    "                            if 'quality' in record.keys():\n",
    "                                face_dict.update({'quality': record['quality']})\n",
    "\n",
    "                            for field_idx, key in enumerate(blazeface.BlazeFace.detection_keys):\n",
    "                                face_dict[key] = frames[frame_idx]['detections'][face_idx][field_idx]\n",
    "\n",
    "                            cropping_bb = adapt_bb(frame_height=fullframe.height,\n",
    "                                                   frame_width=fullframe.width,\n",
    "                                                   bb_height=face_size,\n",
    "                                                   bb_width=face_size,\n",
    "                                                   left=face_dict['xmin'],\n",
    "                                                   top=face_dict['ymin'],\n",
    "                                                   right=face_dict['xmax'],\n",
    "                                                   bottom=face_dict['ymax'])\n",
    "                            face = fullframe.crop(cropping_bb)\n",
    "\n",
    "                            for key in blazeface.BlazeFace.detection_keys:\n",
    "                                if (key[0] == 'k' and key[-1] == 'x') or (key[0] == 'x'):\n",
    "                                    face_dict[key] -= cropping_bb[0]\n",
    "                                elif (key[0] == 'k' and key[-1] == 'y') or (key[0] == 'y'):\n",
    "                                    face_dict[key] -= cropping_bb[1]\n",
    "\n",
    "                            face_dict['left'] = face_dict.pop('xmin')\n",
    "                            face_dict['top'] = face_dict.pop('ymin')\n",
    "                            face_dict['right'] = face_dict.pop('xmax')\n",
    "                            face_dict['bottom'] = face_dict.pop('ymax')\n",
    "\n",
    "                            face_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "                            images_to_save.append((face, face_path))\n",
    "\n",
    "                            video_face_dict_list.append(face_dict)\n",
    "\n",
    "            if len(video_face_dict_list) > 0:\n",
    "\n",
    "                df_video_faces = pd.DataFrame(video_face_dict_list)\n",
    "                df_video_faces.index = df_video_faces['facepath']\n",
    "                del df_video_faces['facepath']\n",
    "\n",
    "                # type conversions\n",
    "                for key in ['kp1x', 'kp1y', 'kp2x', 'kp2y', 'kp3x', 'kp3y',\n",
    "                            'kp4x', 'kp4y', 'kp5x', 'kp5y', 'kp6x', 'kp6y', 'left', 'top',\n",
    "                            'right', 'bottom']:\n",
    "                    df_video_faces[key] = df_video_faces[key].astype(np.int16)\n",
    "                df_video_faces['conf'] = df_video_faces['conf'].astype(np.float32)\n",
    "                df_video_faces['video'] = df_video_faces['video'].astype('category')\n",
    "\n",
    "                video_faces_checkpoint_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            else:\n",
    "                print('No faces extracted for video {}'.format(record['path']))\n",
    "                df_video_faces = pd.DataFrame()\n",
    "\n",
    "            return df_video_faces, video_faces_checkpoint_path, images_to_save\n",
    "\n",
    "        except Exception as e:\n",
    "            print('Error while processing: {}'.format(record['path']))\n",
    "            print(\"-\" * 60)\n",
    "            traceback.print_exc(file=sys.stdout, limit=5)\n",
    "            print(\"-\" * 60)\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(argv):\n",
    "    args = parse_args(argv)\n",
    "\n",
    "    ## Parameters parsing\n",
    "    device: torch.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    source_dir: Path = '/home/eferreira/master/storage/celeb/celebdf'\n",
    "    facedestination_dir: Path = 'faces'\n",
    "    frames_per_video: int = 32\n",
    "    videodataset_path: Path = args.videodf\n",
    "    facesdataset_path: Path = args.facesdf\n",
    "    collateonly: bool = args.collateonly\n",
    "    batch_size: int = args.batch\n",
    "    threads: int = args.threads\n",
    "    offset: int = args.offset\n",
    "    num: int = args.num\n",
    "    lazycheck: bool = args.lazycheck\n",
    "    deepcheck: bool = args.deepcheck\n",
    "    checkpoint_folder: Path = args.checkpoint\n",
    "    index_enable: bool = args.noindex\n",
    "\n",
    "    ## Parameters\n",
    "    face_size = 224\n",
    "\n",
    "    print('Loading video DataFrame')\n",
    "    df_videos = pd.read_pickle(videodataset_path)\n",
    "\n",
    "    if num > 0:\n",
    "        df_videos_process = df_videos.iloc[offset:offset + num]\n",
    "    else:\n",
    "        df_videos_process = df_videos.iloc[offset:]\n",
    "\n",
    "    if not collateonly:\n",
    "\n",
    "        ## Blazeface loading\n",
    "        print('Loading face extractor')\n",
    "        facedet = BlazeFace().to(device)\n",
    "        facedet.load_weights(\"blazeface/blazeface.pth\")\n",
    "        facedet.load_anchors(\"blazeface/anchors.npy\")\n",
    "        videoreader = VideoReader(verbose=False)\n",
    "        video_read_fn = lambda x: videoreader.read_frames(x, num_frames=frames_per_video)\n",
    "        face_extractor = FaceExtractor(video_read_fn, facedet)\n",
    "\n",
    "        ## Face extraction\n",
    "        with ThreadPoolExecutor(threads) as p:\n",
    "            for batch_idx0 in tqdm(np.arange(start=0, stop=len(df_videos_process), step=batch_size),\n",
    "                                   desc='Extracting faces'):\n",
    "                tosave_list = list(p.map(partial(process_video,\n",
    "                                                 source_dir=source_dir,\n",
    "                                                 facedestination_dir=facedestination_dir,\n",
    "                                                 checkpoint_folder=checkpoint_folder,\n",
    "                                                 face_size=face_size,\n",
    "                                                 face_extractor=face_extractor,\n",
    "                                                 lazycheck=lazycheck,\n",
    "                                                 deepcheck=deepcheck,\n",
    "                                                 ),\n",
    "                                         df_videos_process.iloc[batch_idx0:batch_idx0 + batch_size].iterrows()))\n",
    "\n",
    "                for tosave in tosave_list:\n",
    "                    if tosave is not None:\n",
    "                        if len(tosave[2]):\n",
    "                            list(p.map(save_jpg, tosave[2]))\n",
    "                        tosave[1].parent.mkdir(parents=True, exist_ok=True)\n",
    "                        tosave[0].to_pickle(str(tosave[1]))\n",
    "\n",
    "    if index_enable:\n",
    "        # Collect checkpoints\n",
    "        df_videos['nfaces'] = np.zeros(len(df_videos), np.uint8)\n",
    "        faces_dataset = []\n",
    "        for idx, record in tqdm(df_videos.iterrows(), total=len(df_videos), desc='Collecting faces results'):\n",
    "            # Checkpoint\n",
    "            video_face_checkpoint_path = checkpoint_folder.joinpath(record['path']).with_suffix('.faces.pkl')\n",
    "            if video_face_checkpoint_path.exists():\n",
    "                try:\n",
    "                    df_video_faces = pd.read_pickle(str(video_face_checkpoint_path))\n",
    "                    # Fix same attribute issue\n",
    "                    df_video_faces = df_video_faces.rename(columns={'subject': 'videosubject'}, errors='ignore')\n",
    "                    nfaces = len(\n",
    "                        np.unique(df_video_faces.index.map(lambda x: int(x.split('_subj')[1].split('.jpg')[0]))))\n",
    "                    df_videos.loc[idx, 'nfaces'] = nfaces\n",
    "                    faces_dataset.append(df_video_faces)\n",
    "                except Exception as e:\n",
    "                    print('Error while reading: {}'.format(video_face_checkpoint_path))\n",
    "                    print(e)\n",
    "                    video_face_checkpoint_path.unlink()\n",
    "\n",
    "        if len(faces_dataset) == 0:\n",
    "            raise ValueError(f'No checkpoint found from face extraction. '\n",
    "                             f'Is the the source path {source_dir} correct for the videos in your dataframe?')\n",
    "\n",
    "        # Save videos with updated faces\n",
    "        print('Saving videos DataFrame to {}'.format(videodataset_path))\n",
    "        df_videos.to_pickle(str(videodataset_path))\n",
    "\n",
    "        if offset > 0:\n",
    "            if num > 0:\n",
    "                if facesdataset_path.is_dir():\n",
    "                    facesdataset_path = facesdataset_path.joinpath(\n",
    "                        'faces_df_from_video_{}_to_video_{}.pkl'.format(offset, num + offset))\n",
    "                else:\n",
    "                    facesdataset_path = facesdataset_path.parent.joinpath(\n",
    "                        str(facesdataset_path.parts[-1]).split('.')[0] + '_from_video_{}_to_video_{}.pkl'.format(offset,\n",
    "                                                                                                                 num + offset))\n",
    "            else:\n",
    "                if facesdataset_path.is_dir():\n",
    "                    facesdataset_path = facesdataset_path.joinpath('faces_df_from_video_{}.pkl'.format(offset))\n",
    "                else:\n",
    "                    facesdataset_path = facesdataset_path.parent.joinpath(\n",
    "                        str(facesdataset_path.parts[-1]).split('.')[0] + '_from_video_{}.pkl'.format(offset))\n",
    "        elif num > 0:\n",
    "            if facesdataset_path.is_dir():\n",
    "                facesdataset_path = facesdataset_path.joinpath(\n",
    "                    'faces_df_from_video_{}_to_video_{}.pkl'.format(0, num))\n",
    "            else:\n",
    "                facesdataset_path = facesdataset_path.parent.joinpath(\n",
    "                    str(facesdataset_path.parts[-1]).split('.')[0] + '_from_video_{}_to_video_{}.pkl'.format(0, num))\n",
    "        else:\n",
    "            if facesdataset_path.is_dir():\n",
    "                facesdataset_path = facesdataset_path.joinpath('faces_df.pkl')  # just a check if the path is a dir\n",
    "\n",
    "        # Creates directory (if doesn't exist)\n",
    "        facesdataset_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        print('Saving faces DataFrame to {}'.format(facesdataset_path))\n",
    "        df_faces = pd.concat(faces_dataset, axis=0, )\n",
    "        df_faces['video'] = df_faces['video'].astype('category')\n",
    "        for key in ['kp1x', 'kp1y', 'kp2x', 'kp2y', 'kp3x',\n",
    "                    'kp3y', 'kp4x', 'kp4y', 'kp5x', 'kp5y', 'kp6x', 'kp6y', 'left',\n",
    "                    'top', 'right', 'bottom', ]:\n",
    "            df_faces[key] = df_faces[key].astype(np.int16)\n",
    "        df_faces['videosubject'] = df_faces['videosubject'].astype(np.int8)\n",
    "        # Eventually remove duplicates\n",
    "        df_faces = df_faces.loc[~df_faces.index.duplicated(keep='first')]\n",
    "        fields_to_preserve_from_video = [i for i in\n",
    "                                         ['folder', 'subject', 'scene', 'cluster', 'nfaces', 'test'] if\n",
    "                                         i in df_videos]\n",
    "        df_faces = pd.merge(df_faces, df_videos[fields_to_preserve_from_video], left_on='video',\n",
    "                            right_index=True)\n",
    "        df_faces.to_pickle(str(facesdataset_path))\n",
    "\n",
    "    print('Completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp_01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
